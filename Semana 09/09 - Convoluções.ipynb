{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/alan-barzilay/NLPortugues/blob/master/imagens/logo_nlportugues.png?raw=true\"  style=\"height:65%\" align=\"right\">\n",
    "\n",
    "\n",
    "# Lista 9 -  Convoluções\n",
    "**Nome:**\n",
    "\n",
    "**Numero Usp:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "______________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O objetivo desta lista é fazer com que vocês se familiarizem com redes convolucionais, vocês ja tiveram um contato breve com essa arquitetura algumas listas atrás mas dessa vez vocês cuidarão sozinhos da implementação e deverão tomar medidas para evitar overfitting. Novamente, as questões 1 2 e 3 podem ser copiadas de listas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from unidecode import unidecode\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, Dropout, Input, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando os dados como um dataframe\n",
    "\n",
    "Para esta lista nós utilizaremos o dataset **B2W-Reviews01** que consiste em avaliações de mais de 130k compras online no site Americanas.com e [esta disponivel no github](https://github.com/b2wdigital/b2w-reviews01) sob a licensa CC BY-NC-SA 4.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>estou contente com a compra entrega rapida o u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>por apenas r$1994.20,eu consegui comprar esse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>supera em agilidade e praticidade outras panel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>meu filho amou! parece de verdade com tantos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>a entrega foi no prazo, as americanas estao de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recommend_to_a_friend                                        review_text\n",
       "0                   Yes  estou contente com a compra entrega rapida o u...\n",
       "1                   Yes  por apenas r$1994.20,eu consegui comprar esse ...\n",
       "2                   Yes  supera em agilidade e praticidade outras panel...\n",
       "3                   Yes  meu filho amou! parece de verdade com tantos d...\n",
       "4                   Yes  a entrega foi no prazo, as americanas estao de..."
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus = pd.read_csv(\"../Semana 03/data/B2W-Reviews01.csv\",\";\",usecols=['review_text','recommend_to_a_friend'], encoding='utf-8',nrows=25000)\n",
    "for i, row in b2wCorpus.iterrows():\n",
    "    ifor_val = unidecode(row['review_text']).lower()\n",
    "    b2wCorpus.at[i,'review_text']= ifor_val\n",
    "b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        estou contente com a compra entrega rapida o u...\n",
       "1        por apenas r$1994.20,eu consegui comprar esse ...\n",
       "2        supera em agilidade e praticidade outras panel...\n",
       "3        meu filho amou! parece de verdade com tantos d...\n",
       "4        a entrega foi no prazo, as americanas estao de...\n",
       "                               ...                        \n",
       "24995    ameii a fralda, pois ela se adequoa perfeitame...\n",
       "24996    gostei corresponde as expectativas chegou ante...\n",
       "24997    gostei mt apesar de ter usado  pouco , recomen...\n",
       "24998    produto muito bom, o unico problema e que as t...\n",
       "24999    produto muito potente, de alta qualidade e mui...\n",
       "Name: review_text, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"review_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pré-processamento\n",
    "Seria util nos livrarmos das colunas que não são relevantes para o nosso problema e tambem verificar se não tem nada de esquisito nas colunas que vamos utilizar. \n",
    "Por exemplo, se fossemos utilizar a coluna \"reviewer_gender\" nós precisariamos nos livrar desses valores esquisitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2wCorpus[\"reviewer_gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Questão 1 </font>\n",
    "\n",
    "a) Selecione apenas as colunas relevantes: \"review_text\" e \"recommend_to_a_friend\". \n",
    "\n",
    "b) Converta a coluna \"recommend_to_a_friend\" de uma coluna de `str` para uma coluna de `int`:\n",
    "\n",
    "- \"Yes\"-> 1\n",
    "- \"No\" -> 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    18862\n",
       "0.0     6136\n",
       "Name: recommend_to_a_friend, dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus['recommend_to_a_friend'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "b2wCorpus.head()\n",
    "b2wCorpus[\"recommend_to_a_friend\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando em teste e treino\n",
    "## <font color='blue'>Questão 2 </font>\n",
    "\n",
    "Agora com o dataset já pré-processado, separe o em 2 partes, um conjunto de teste e um conjunto de treino. Novamente você pode utilizar a função [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do Scikit-Learn como na lista passada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "x = b2wCorpus[['review_text']].values.astype('str')\n",
    "y = b2wCorpus[['recommend_to_a_friend']].values\n",
    "np.random.seed(RANDOM_SEED)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizando\n",
    "\n",
    "Para alimentarmos os reviews a camada de embedding nós precisamos quebrar cada review em uma serie de tokens. Existem diversas maneiras de se realizar isso e poderiamos até mesmo usar outras bibliotecas como o spaCy. \n",
    "\n",
    "Por exemplo, o objeto [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) oferece um método `tokenize` para quebrar as palavras em tokens individuais ao mesmo tempo que filtra caracteres indesejados (por default os caracteres filtrados são: !\"#$\\%&()*+,-./:;<=>?@[\\\\]^_\\`{|}~\\t\\n).\n",
    "\n",
    "\n",
    "Para essa lista utilizaremos a camada [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) para automaticamente passar os reviews para caixa-baixa, extrair caracteres especiais e tokenizar as palavras de maneira a serem passadas para a camada de embedding. Ao tornarmos a etapa de tokenização uma camada de rede neural nós podemos incluir esse processamento dos reviews no proprio modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Questão 3 </font>\n",
    "Utilizando a camada `TextVectorization` tokenize os inputs.\n",
    "Declare a camada e então chame a função `adapt()` para adequar o seu vocabulário aos reviews.\n",
    "\n",
    "Não se esqueça de se certificar que todas os reviews tenham o mesmo comprimento, seja por meio do uso de padding, truncamento ou uma mistura dos dois. Plotamos um histograma do comprimento dos reviews para lhe auxiliar nessa decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(linha.split()) for linha in b2wCorpus[\"review_text\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12628\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_MAXLEN = 50\n",
    "vectorize_layer = TextVectorization(\n",
    "                                        max_tokens=12628,\n",
    "                                        standardize='lower_and_strip_punctuation',\n",
    "                                        output_mode='int',\n",
    "                                        pad_to_max_tokens=False,\n",
    "                                        output_sequence_length=SEQUENCE_MAXLEN\n",
    "                                        )\n",
    "\n",
    "vectorize_layer.adapt(x_train)\n",
    "vocab_size = len(vectorize_layer.get_vocabulary())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando o modelo\n",
    "\n",
    "Agora vamos juntar a camada do tokenizador a nossa camada [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) e definir o resto de nosso modelo.\n",
    "\n",
    "##  <font color='blue'>Questão 4 </font>\n",
    "\n",
    "Defina seu modelo.\n",
    "\n",
    "Como analise de sentimentos pode ser visto como um problema de classificação, é interessante também registrar algumas métricas como acurácia `metrics=[\"acc\"]` .\n",
    "\n",
    "Seu modelo deve começar com a seguinte estrutura:\n",
    " - Camada de Input\n",
    " - Camada de Tokenização\n",
    " - Camada de Embedding\n",
    " \n",
    "Já definimos as camadas seguintes da rede por você.\n",
    " \n",
    "Atenção a dimensão do input da camada de embedding, lembre se que < OOV > e < PAD > possuem seus próprios tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 128\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(1, ), dtype=tf.string))\n",
    "model.add(vectorize_layer)\n",
    "model.add(Embedding(vocab_size + 2, dim, input_length=SEQUENCE_MAXLEN))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=16, activation='relu', input_shape=(SEQUENCE_MAXLEN, dim), padding='same'))\n",
    "model.add(AveragePooling1D(pool_size=3, padding='valid'))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=64, activation='relu', input_shape=(SEQUENCE_MAXLEN, dim), padding='same'))\n",
    "model.add(AveragePooling1D(pool_size=3, padding='valid'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "#model = Sequential()\n",
    "#model.add(Input(shape=(1, ), dtype=tf.string))\n",
    "#model.add(vectorize_layer)\n",
    "#model.add(Embedding(vocab_size+2, 128, input_length=SEQUENCE_MAXLEN))\n",
    "#model.add(Conv1D(filters=200, kernel_size=32, activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando seu modelo\n",
    "\n",
    "##  <font color='blue'>Questão 5 </font>\n",
    "\n",
    "Com seu modelo definido, treine e avalie sua performance no conjunto de testes, utilize camadas [Conv1D](https://keras.io/api/layers/convolution_layers/convolution1d/) na sua rede.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "310/625 [=============>................] - ETA: 7s - loss: nan - accuracy: 0.5840"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-262-f9822954f6a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m )\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\ep2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, clipvalue=5.0)\n",
    "opt= \"adam\"\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "#lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#    initial_learning_rate=1e-3,\n",
    "#    decay_steps=1000000,\n",
    "#    decay_rate=0.09)\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "#opt = tf.keras.optimizers.RMSprop(\n",
    "#    learning_rate=0.001,\n",
    "#    rho=0.9,\n",
    "#    momentum=0.0,\n",
    "#    epsilon=1e-07,\n",
    "#    centered=False,\n",
    "#    name=\"RMSprop\"\n",
    "#)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
