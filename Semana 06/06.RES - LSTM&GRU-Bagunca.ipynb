{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/alan-barzilay/NLPortugues/blob/master/imagens/logo_nlportugues.png?raw=true\"  style=\"height:65%\" align=\"right\">\n",
    "\n",
    "\n",
    "# Lista 6 - LSTM&GRU \n",
    "**Nome:**\n",
    "\n",
    "**Numero Usp:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "______________\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O objetivo desta lista é fazer com que vocês treinem um modelo de análise de sentimentos utilizando GRU's e LSTM's. Essa lista é semelhante a lista 03 onde aprendemos a usar embeddings e onde você ja recebeu a arquitetura do seu modelo quase pronta. A diferença é que desta vez você ira construir sozinho sua rede e utilizará as camadas que acabamos de aprender: LSTM e GRU.\n",
    " \n",
    "Essa tambêm será a primeira rede recorrente que montaremos, portanto a tokenização será ligeiramente diferente (por exemplo o padding não é mais necessário.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "# '2.2.0-rc3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os dados como um dataframe\n",
    "\n",
    "Para esta lista nós utilizaremos um recorte de 10 mil linhas do dataset **B2W-Reviews01** que consiste em avaliações de mais de 130k compras online no site Americanas.com e [esta disponivel no github](https://github.com/b2wdigital/b2w-reviews01) sob a licensa CC BY-NC-SA 4.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>site_category_lv1</th>\n",
       "      <th>site_category_lv2</th>\n",
       "      <th>review_title</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>recommend_to_a_friend</th>\n",
       "      <th>review_text</th>\n",
       "      <th>reviewer_birth_year</th>\n",
       "      <th>reviewer_gender</th>\n",
       "      <th>reviewer_state</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:11:28</td>\n",
       "      <td>d0fb1ca69422530334178f5c8624aa7a99da47907c44de...</td>\n",
       "      <td>132532965</td>\n",
       "      <td>Notebook Asus Vivobook Max X541NA-GO472T Intel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Informática</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Bom</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
       "      <td>1958</td>\n",
       "      <td>F</td>\n",
       "      <td>RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:13:48</td>\n",
       "      <td>014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...</td>\n",
       "      <td>22562178</td>\n",
       "      <td>Copo Acrílico Com Canudo 500ml Rocie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utilidades Domésticas</td>\n",
       "      <td>Copos, Taças e Canecas</td>\n",
       "      <td>Preço imbatível, ótima qualidade</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
       "      <td>1996</td>\n",
       "      <td>M</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:26:02</td>\n",
       "      <td>44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...</td>\n",
       "      <td>113022329</td>\n",
       "      <td>Panela de Pressão Elétrica Philips Walita Dail...</td>\n",
       "      <td>philips walita</td>\n",
       "      <td>Eletroportáteis</td>\n",
       "      <td>Panela Elétrica</td>\n",
       "      <td>ATENDE TODAS AS EXPECTATIVA.</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
       "      <td>1984</td>\n",
       "      <td>M</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:35:54</td>\n",
       "      <td>ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...</td>\n",
       "      <td>113851581</td>\n",
       "      <td>Betoneira Columbus - Roma Brinquedos</td>\n",
       "      <td>roma jensen</td>\n",
       "      <td>Brinquedos</td>\n",
       "      <td>Veículos de Brinquedo</td>\n",
       "      <td>presente mais que desejado</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
       "      <td>1985</td>\n",
       "      <td>F</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 01:00:28</td>\n",
       "      <td>7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...</td>\n",
       "      <td>131788803</td>\n",
       "      <td>Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...</td>\n",
       "      <td>lg</td>\n",
       "      <td>TV e Home Theater</td>\n",
       "      <td>TV</td>\n",
       "      <td>Sem duvidas, excelente</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
       "      <td>1994</td>\n",
       "      <td>M</td>\n",
       "      <td>MG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       submission_date                                        reviewer_id  \\\n",
       "0  2018-01-01 00:11:28  d0fb1ca69422530334178f5c8624aa7a99da47907c44de...   \n",
       "1  2018-01-01 00:13:48  014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...   \n",
       "2  2018-01-01 00:26:02  44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...   \n",
       "3  2018-01-01 00:35:54  ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...   \n",
       "4  2018-01-01 01:00:28  7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...   \n",
       "\n",
       "   product_id                                       product_name  \\\n",
       "0   132532965  Notebook Asus Vivobook Max X541NA-GO472T Intel...   \n",
       "1    22562178               Copo Acrílico Com Canudo 500ml Rocie   \n",
       "2   113022329  Panela de Pressão Elétrica Philips Walita Dail...   \n",
       "3   113851581               Betoneira Columbus - Roma Brinquedos   \n",
       "4   131788803  Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...   \n",
       "\n",
       "    product_brand      site_category_lv1       site_category_lv2  \\\n",
       "0             NaN            Informática                Notebook   \n",
       "1             NaN  Utilidades Domésticas  Copos, Taças e Canecas   \n",
       "2  philips walita        Eletroportáteis         Panela Elétrica   \n",
       "3     roma jensen             Brinquedos   Veículos de Brinquedo   \n",
       "4              lg      TV e Home Theater                      TV   \n",
       "\n",
       "                       review_title  overall_rating recommend_to_a_friend  \\\n",
       "0                               Bom               4                   Yes   \n",
       "1  Preço imbatível, ótima qualidade               4                   Yes   \n",
       "2      ATENDE TODAS AS EXPECTATIVA.               4                   Yes   \n",
       "3        presente mais que desejado               4                   Yes   \n",
       "4            Sem duvidas, excelente               5                   Yes   \n",
       "\n",
       "                                         review_text reviewer_birth_year  \\\n",
       "0  Estou contente com a compra entrega rápida o ú...                1958   \n",
       "1  Por apenas R$1994.20,eu consegui comprar esse ...                1996   \n",
       "2  SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...                1984   \n",
       "3  MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...                1985   \n",
       "4  A entrega foi no prazo, as americanas estão de...                1994   \n",
       "\n",
       "  reviewer_gender reviewer_state Unnamed: 14 Unnamed: 15 Unnamed: 16  \\\n",
       "0               F             RJ         NaN         NaN         NaN   \n",
       "1               M             SC         NaN         NaN         NaN   \n",
       "2               M             SP         NaN         NaN         NaN   \n",
       "3               F             SP         NaN         NaN         NaN   \n",
       "4               M             MG         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 17 Unnamed: 18  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus = pd.read_csv(\"../data/b2w-10k.csv\")\n",
    "b2wCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Estou contente com a compra entrega rápida o ú...\n",
       "1       Por apenas R$1994.20,eu consegui comprar esse ...\n",
       "2       SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...\n",
       "3       MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...\n",
       "4       A entrega foi no prazo, as americanas estão de...\n",
       "                              ...                        \n",
       "9994    Celular muito rápido, com processador e armaze...\n",
       "9995    achei o produto muito frágil, o material veio ...\n",
       "9996    Uma porcaria pois ñ recebi ñ recomendo pra nin...\n",
       "9997    Maquina excelente,super pratica. recomendo.ent...\n",
       "9998    Agradeço pelo compromisso, obrigado. ,...........\n",
       "Name: review_text, Length: 9999, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2wCorpus[\"review_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pré-processamento \n",
    "# <font color='blue'>Questão 1 </font>\n",
    "Copie suas etapas de préprocessamento da lista 03, ou seja, selecione apenas as colunas relevantes (\"review_text\" e \"recommend_to_a_friend\"), converta a coluna \"review_text\" de uma coluna de `str` para uma coluna de `int` e separe os dados em teste e treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dados/home/wseidel/envs/usp-MAC5725b/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8674    Entrega rápida! E o produto de excelente quali...\n",
       "8024    recebi meu produto muito rapido, adorei o prod...\n",
       "4083    contudo, só não comprei porque aprecio ver alg...\n",
       "4089    Comprei com capa protetora e foi enviado um le...\n",
       "6420    Excelente produto, cumpre o que promete..........\n",
       "                              ...                        \n",
       "8470    Pra fotos ele é ÓTIMO  PARA AS DEMAIS FUNÇÕES ...\n",
       "6061    produto normal umo produto como tantos outas  ...\n",
       "9529    Comprei duas unidades, quando usei um logo que...\n",
       "406     O produto é até bom, mas a foi pessíma no aten...\n",
       "2191    O produto não tem muito a ver com a imagem ilu...\n",
       "Name: review_text, Length: 7999, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "\n",
    "df = b2wCorpus[['review_text','recommend_to_a_friend']]\n",
    "df['recommend_to_a_friend'] = df['recommend_to_a_friend'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review_text'], df['recommend_to_a_friend'], test_size=0.20, random_state=17)\n",
    "# [X_train, y_train]\n",
    "\n",
    "# df.head()\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizando\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Questão 2 </font>\n",
    "Utilizando a camada [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) tokenize os inputs.\n",
    "Declare a camada e então chame a função `adapt()` no seu conjunto de treino para adequar o seu vocabulário aos reviews. \n",
    "\n",
    "Note que o uso de padding não é mais necessario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7999,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "MAX_SENTENCE_LENGTH = 75\n",
    "EMBEDDING_LENGTH = 128\n",
    "QNT_EPOCAS_A_TESTAR = 1\n",
    "\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_sequence_length=MAX_SENTENCE_LENGTH,  # Only valid in INT mode.\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32,  44,   4,   1, 104, 189, 944,   1,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/you-should-try-the-new-tensorflows-textvectorization-layer-a80b3c6b00ee\n",
    "# https://stackoverflow.com/questions/63207118/unable-to-concatenate-features-to-same-shape\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "input_ = layers.Input(shape=(1,), dtype=tf.string)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(input_)\n",
    "model.add(vectorize_layer)\n",
    "model.predict([\"Eu gostei de passear pela casa ontem daskdaslçlk\"])\n",
    "# model.predict(\n",
    "# [ \n",
    "#   [\"Entrega rápida! E o produto de\"],\n",
    "#   [\"klksa kkjhdjs oppoi dndasd \"]\n",
    "# ]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM&GRU\n",
    "\n",
    "Agora vamos juntar a camada do tokenizador a nossa camada [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) e definir o resto de nosso modelo.\n",
    "\n",
    "#  <font color='blue'>Questão 3 </font>\n",
    "\n",
    "a) Defina, compile, treine e avalie seu modelo, utilize camadas  [LSTM](https://keras.io/api/layers/recurrent_layers/lstm/).\n",
    "Atenção a dimensão do input da camada de embedding, lembre se que < OOV > e < PAD > possuem seus próprios tokens.\n",
    " \n",
    " \n",
    " \n",
    "b) Como foi a performance desta rede em comparação a da lista 3?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Sua resposta aqui </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.4982 - acc: 0.7525\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.4412 - acc: 0.7920\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.4358 - acc: 0.7975\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.4707 - acc: 0.7671ETA: 1\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4896 - acc: 0.7700\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_30 (TextV (None, 63)                0         \n",
      "_________________________________________________________________\n",
      "embedding_44 (Embedding)     (None, 63, 128)           640128    \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 771,841\n",
      "Trainable params: 771,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.4060 - acc: 0.8090\n",
      "Loss:  0.4059552848339081\n",
      "Accuracy:  0.8090000152587891\n"
     ]
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE+1, output_dim=EMBEDDING_LENGTH, input_length=MAX_SENTENCE_LENGTH),\n",
    "    tf.keras.layers.LSTM(\n",
    "        units=EMBEDDING_LENGTH, \n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "    ),\n",
    "    \n",
    "\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4, seed=random.randint(0,15)),\n",
    "    \n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"acc\"])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=QNT_EPOCAS_A_TESTAR)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "loss, accuracy = model.evaluate(x=X_test,y=y_test)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='blue'>Questão 4 </font>\n",
    "\n",
    "a) Defina, compile, treine e avalie seu modelo, utilize camadas [GRU](https://keras.io/api/layers/recurrent_layers/gru/).\n",
    "Atenção a dimensão do input da camada de embedding, lembre se que < OOV > e < PAD > possuem seus próprios tokens.\n",
    " \n",
    " \n",
    " \n",
    "b) Como foi a performance desta rede em comparação a da lista 3?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Sua resposta aqui </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 15s 59ms/step - loss: 0.5606 - acc: 0.7477\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_30 (TextV (None, 63)                0         \n",
      "_________________________________________________________________\n",
      "embedding_46 (Embedding)     (None, 63, 128)           640128    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 739,329\n",
      "Trainable params: 739,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.5505 - acc: 0.7535\n",
      "Loss:  0.5504764318466187\n",
      "Accuracy:  0.7534999847412109\n"
     ]
    }
   ],
   "source": [
    "# Seu código aqui\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE+1, output_dim=EMBEDDING_LENGTH, input_length=MAX_SENTENCE_LENGTH),\n",
    "    tf.keras.layers.GRU(\n",
    "        units=EMBEDDING_LENGTH, \n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "    ),\n",
    "    layers.Dropout(0.4, seed=random.randint(0,15)),\n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"acc\"])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "loss, accuracy = model.evaluate(x=X_test,y=y_test)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Bi-direcionais\n",
    "#  <font color='blue'>Questão 5 </font>\n",
    "\n",
    "a) Defina, compile, treine e avalie um novo modelo que utilize contexto em ambas as direções usando a camada [`Bidirectional()`](https://keras.io/api/layers/recurrent_layers/bidirectional/), seja com camadas GRU ou LSTM.\n",
    "\n",
    "\n",
    "b) Como foi sua performance em relação as questões anteriores com contexto unidirecional?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Sua resposta aqui </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE+1, output_dim=EMBEDDING_LENGTH, input_length=MAX_SENTENCE_LENGTH),\n",
    "    tf.keras.layers.GRU(\n",
    "        units=EMBEDDING_LENGTH, \n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "    ),\n",
    "    layers.Dropout(0.4, seed=random.randint(0,15)),\n",
    "    layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"acc\"])\n",
    "\n",
    "model.fit(X_train, y_train,epochs=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "loss, accuracy = model.evaluate(x=X_test,y=y_test)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
